{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports cell\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "from facexlib.detection import init_detection_model\n",
    "from facexlib.utils.face_restoration_helper import FaceRestoreHelper\n",
    "from PIL import Image\n",
    "from IPython.display import display, Image as IPImage\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Setup cell\n",
    "def check_dependencies():\n",
    "    required_packages = {\n",
    "        'torch': 'torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu',\n",
    "        'opencv-python': 'opencv-python',\n",
    "        'basicsr': 'basicsr',\n",
    "        'facexlib': 'facexlib'\n",
    "    }\n",
    "    \n",
    "    for package, install_cmd in required_packages.items():\n",
    "        try:\n",
    "            __import__(package)\n",
    "            print(f\"{package} already installed\")\n",
    "        except ImportError:\n",
    "            print(f\"Installing {package}...\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", install_cmd])\n",
    "\n",
    "# Model and processing cell\n",
    "def load_model(model_path):\n",
    "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32)\n",
    "    model.load_state_dict(torch.load(model_path, map_location='mps'))\n",
    "    model.eval()\n",
    "    return model.to('mps') if torch.backends.mps.is_available() else model.cpu()\n",
    "\n",
    "def process_face(img_path, model_path, output_path, scale=4):\n",
    "    device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "    face_detector = init_detection_model('retinaface_resnet50', device=device)\n",
    "    face_helper = FaceRestoreHelper(upscale_factor=scale)\n",
    "    \n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        print(f\"Failed to load image: {img_path}\")\n",
    "        return False\n",
    "        \n",
    "    face_helper.read_image(img)\n",
    "    \n",
    "    print(f\"Processing {img_path.name}...\")\n",
    "    print(\"Detecting faces...\")\n",
    "    face_helper.detect_faces(face_detector)\n",
    "    face_helper.align_warp_face()\n",
    "    \n",
    "    if len(face_helper.cropped_faces) == 0:\n",
    "        print(\"No faces detected!\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"Found {len(face_helper.cropped_faces)} faces\")\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    for idx, cropped_face in enumerate(face_helper.cropped_faces):\n",
    "        print(f\"Processing face {idx+1}...\")\n",
    "        cropped_face_t = torch.from_numpy(cropped_face).float() / 255.\n",
    "        cropped_face_t = cropped_face_t.permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(cropped_face_t)\n",
    "        \n",
    "        output = output.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "        output = (output * 255.0).round().astype(np.uint8)\n",
    "        face_helper.add_restored_face(output)\n",
    "    \n",
    "    face_helper.get_inverse_affine(None)\n",
    "    restored_img = face_helper.paste_faces_to_input_image()\n",
    "    cv2.imwrite(str(output_path), restored_img)\n",
    "    print(f\"Saved result to {output_path.name}\")\n",
    "    return True\n",
    "\n",
    "# Main processing cell\n",
    "def process_folder():\n",
    "    # Setup paths\n",
    "    base_path = Path('py_4x_upscaler')\n",
    "    input_path = base_path / 'input'\n",
    "    model_path = base_path / 'model' / 'upscaler.pth'\n",
    "    output_path = base_path / 'output'\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Validate model exists\n",
    "    if not model_path.exists():\n",
    "        raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
    "    \n",
    "    # Get all images from input folder\n",
    "    image_files = []\n",
    "    for ext in ['.jpg', '.jpeg', '.png']:\n",
    "        image_files.extend(input_path.glob(f'*{ext}'))\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"No images found in input folder!\")\n",
    "        return\n",
    "    \n",
    "    # Process each image\n",
    "    print(f\"Found {len(image_files)} images to process\")\n",
    "    for img_path in tqdm(image_files, desc=\"Processing images\"):\n",
    "        output_file = output_path / f\"{img_path.stem}_4xUpscaled{img_path.suffix}\"\n",
    "        process_face(img_path, model_path, output_file)\n",
    "\n",
    "# Execution cell\n",
    "if __name__ == \"__main__\":\n",
    "    check_dependencies()\n",
    "    process_folder()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
